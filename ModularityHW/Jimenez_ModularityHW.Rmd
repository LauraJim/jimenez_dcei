---
title: "Changes in temperature and precipitation over the past 60 years in the USA"
author: "Laura Jiménez"
date: "March 2018"
output: pdf_document
bibliography: ModularityHW_refs.bib
csl: Science.csl
fontsize: 11pt
---

<!--***DAN: To find my comments, search for "***DAN:"-->

<!--***DAN: Your use of git is excellent, lots of commits, with informative commit messages, so great on that count!-->

<!--***DAN: The write-up is definitely adequate for this assignment, with clear-enough text, references, etc. And the figures look nice and are well-enough integrated.-->

<!--***DAN: You skipped a part of the assignment, namely inserting comments indicating which of the 10 "rules of modularity" we learned in class were applied where in your code. The grade is based on effortful completion of all parts of the assignment. Ordinarily, I have been subtracting points for not doing that part of the assignment and giving people the chance to go back and add those comments. HOWEVER you have done a really great job of implementing basically all the lessons of modularity we have learned, so much so that it is quite transparent where you have applied them. So it would be a waste of time to go back and add the comments. So you get 10/10 for effortful completion of all parts of the assignment. Nevertheless, as you already recognize, there are things that did not work and opportunities for further improvment, so I recommend you read all the comments below and study the solutions I have provided.-->

```{r setup, include=F}
knitr::opts_chunk$set(echo = F)
```

<!--***DAN: the tempdir() call is a problem here, apparently each new Rmd knit makes a new R session, and that causes tempdir to generate a new temporary directory. That means each time checkpoint creates a new local repository for allt he packages uses, and of course that can take forever. At least that is what happened when I tried to use checkpoint with tempdir in an Rmd. I was able to get checkpoint to work by making the location where the .checkpoint folder is established be the same as the folder the Rmd file is in, which also has other advantages as far as transportability to another machine is concerned.-->
<!---```{r check, echo=F, cache=T, message=F, warning=F}
library(checkpoint)
dir.create(file.path(tempdir(),".checkpoint"),recursive=T,showwarnings=F)
checkpoint("2018-03-14",checkpointLocation=tempdir())
```-->

```{r extra-code}
# used in chunk "data"
mtime <- function(files)
{
  lapply(Sys.glob(files),function(x) {X = file.info(x)$mtime})
}
# used in chunk "map-trend-temp" and "map-trend-prec"
library(maps)
# used in chunk "data" when 'previded=F'
source("acis2df_jimenez.R")
```

## Abstract

# Introduction
Understanding the observed climate trends for the United States in terms of regional characteristics and hemispheric perspectives is important to assess regional changes and to understand further the global climate system. Further, the anthropogenic climate change signal is projected to be stronger in the high-latitudes [@nicholls1996; @Zhang2000; @Jones1999]. This suggests that it might be easier to detect climate change in a country like the United States of America.  
In this work we analyze climate data from weather stations all around the USA to see if we can detect climate warming. We aim to detect the spatial and temporal characteristics of change in annual mean temperature and annual mean precipitation across the United States along the period $1950-2016$.  

# Methods

## Data

We obtained measurements for temperature (in Farenheit scale) and precipitation (in milimeters?) from weather stations placed along the USA managed by the Applied Climate Information System which can be downloaded from their website [ACIS](http://builder.rcc-acis.org/). For temperature, we got annual means for all the weather stations from $1950$ to $2016$. The precipitaion data are also annual means during the same period but we only considered three states: Alabama, Ohio and Tennessee.

<!--***DAN: Nice work on this comment and manually specifying the dependencies.-->
<!--- Chunk for reading data, you need to give file names and set 'provided'. Dependencies: mtime --->
```{r data, cache=T, cache.extra=list(mtime("USAAnnualTemp1950_2008.rds"),mtime("USAAnnualPcpn1950_2008.rds"))}
# provided == T, if data are stored in the same directory as the code
# provided == F, if the data will be downloaded from a website
provided <- T
files <- c("USAAnnualTemp1950_2008.rds","USAAnnualPcpn1950_2008.rds")
if(provided){
  temp <- readRDS(files[1])
  prec <- readRDS(files[2])
  # both files should be data.frame objects
} else{
# Apply function for downloading temperature data
res1 <- acis2dfpcpn(sdate="19500101", edate="20161231", states=state.abb, elem=1)
fname1 <- paste0("data/USAannualTemp",sdate,"_", edate,".rds")
saveRDS(res1, file=fname1)

# Apply function for downloading precipitation data
res2 <- acis2dfpcpn(sdate="19500101", edate="20161231", states=c("AL","OH","TN"), elem=2)
fname2 <- paste0("data/USAannualPcpn",sdate,"_", edate,".rds")
saveRDS(res2, file=fname2)
}
# #### Formating the downloaded data
# lf <- list.files(pattern="20161231$", path="data/", full.names = T)
# temp <- data.frame()
# for(i in lf[2]){
#   tmp <- readRDS(i)
#   tmp2 <- reshape2::melt(tmp, id.vars="year")
#   temp <- rbind(temp, tmp2)
# }
# temp <- temp[!temp$variable=="NA.",]
# grid <- strsplit(as.character(temp$variable), ",")
# latff <- sapply(grid,"[",2)
# temp$lat <- as.numeric(gsub(x=latff, replacement = "",pattern=" |)"))
# lonff <- sapply(grid,"[",1)
# temp$lon <- as.numeric(sub("\\D+","",lonff))*-1
# temp$state <- substr(temp$variable,1,2)
# library(qdapRegex)
# temp$name <- unlist(rm_between(text.var =lonff, left = "_", right="_", extract=TRUE))
#                   
# saveRDS(temp, "../ModularityHW/USAannualTemp1950_2016.rds")
#}
####
```

<!--- Chunk for cleaning data, you need to set 'minY' when using the function. Dependencies: temp,prec --->
```{r cleaning, cache=T, include=F}
# Function that gets rid of stations with less than a minimum number of observations and transform the data to a matrix
# 'dats' must be a data frame object with the following variables: state, name, lon, lat, data, year
# 'minY' is the minimum number of years that a station must contain to be included in the final dataset
# Output: a matrix with the cleaned data
cleanTP <- function(dats,minY)
{
  # Filtering data by weather station name and removing NA's
  filter1 <- aggregate(data~name,dats,length,na.action = na.omit)
  # Removing the weather stations with less than "minY" years of data
  filter2 <- subset(filter1,filter1$data >= minY)$name
  # Select the stations in filter2 from the original dataset
  filter3 <- subset(dats,subset=dats$name%in%filter2,selec=c(lon,lat,data,year))
  years <- unique(filter3$year)
  nyear <- length(years)
  year01 <- range(years)
  mclean <- matrix(as.vector(filter3$data),nrow=nyear)
  lonlat <- cbind(filter3$lon,filter3$lat)
  return(list(mclean,lonlat,year01))
}

# Now use the function for cleaning both the temperature and the precipitation datasets:
miny <- 40
temp.cl <- cleanTP(dats=temp,minY=miny)
temp.obs <- temp.cl[[1]]
temp.obs[1:8,1:8]
dim(temp.obs)
prec.cl <- cleanTP(prec,40)#***DAN: why did you put 40 here instead of miny?
prec.obs <- prec.cl[[1]]
prec.obs[1:8,1:8]
dim(prec.obs)
#***DAN: Nice use of a function called twice on the two variables - good modularity.
```

Ideally, the period $1950-2016$ includes $67$ observations for each weather station, however, not all these observations were actually stored in the database. Thus, there are a lot of missing values in the raw datasets that we needed to clean. We set a threshold of `r miny` observations per weather station, so that stations with less that `r miny` years of data were left out of the analysis. After removing those stations, we ended up with `r ncol(temp.obs)` stations with enough temperature measurements and `r ncol(prec.obs)` stations with enough precipitation measurements.

## Environmental trends

Some non-parametric tests were developed for assesing environmental impacts because scientists were concerned that the statistical features of messy environmental data would make difficult to use parametric procedures [@Hipel1994; @Haylock2006]. Temperature and precipitation time series may contain one or more of a number of properties which are undesirable for use with parametric tests. Moreover, data are censored or or the time series contain a lot of missing values. We used a nonparametric test which is designed for checking for the presence of a trend that may be contained in the data. So, the outputs may not give an indication of the type or magnitude of the trend. Here, we used the Mann-Kendall trend test which is a special case of the Kendall rank correlation test [@Hipel1994].  
We aplied a Mann-Kendall test to the temperature and precipitation time series to check for the presence of a trend. The Mann-Kendall test is a nonparametric test for randomness against time, i.e., it cotrasts the null hypothesis that the data come from a population where the random variables are independent and identically distributed against the alternative hypothesis that the data follow a monotonic trend over time. We calculated the values of the Mann-Kendall test statistic, S, under the null hypothesis by using the function 'Kendal' in R. A positive value of S indicates that there is an upward trend in which the observations increase with time. A negative value of S means that there is  downward trend. If the value of S is significantly different from zero, we reject the null hypothesis at a chosen significance level (0.95, in our case) and have evidence of the presence of a monotonic trend.

<!--- Chunk for applying Mann-Kendall test, you need to give file names and set 'provided'. Dependencies: temp.obs,prec.obs --->
```{r trends, include=F, cache=T}
# Function that applies a Mann-Kendall test to each column/time series in the matrix 'tseries' a gives as a result a vector with values -1, 0, 1 where -1 indicates a negative trend, 1 indicates a positive trend and 0 means that the statistic is not significantly different from zero (no significant trend detected)
MKapply <- function(tseries,alpha)
{
  nsts <- ncol(tseries)
  scores <- rep(0,nsts)
for(j in 1:nsts)
{
  res <- Kendall::MannKendall(tseries[,j])
  if(res$sl[1]<alpha) # reject the null hypothesis
  {
    if(res$S[1]>0) # positive trend
      scores[j] <- 1
    else # negative trend
      scores[j] <- -1
  }
}
  return(scores)
}

# Use the function to calculate the scores for temperature and precipitation data
tscores <- MKapply(temp.obs,alpha = 0.95)
pscores <- MKapply(prec.obs,alpha = 0.95)
# these scores will be used in a following chunk
#***DAN: another good instance of modularity
```

# Results

Figure 1 shows the time series from a sample of weather stations that we used for the trend analysis. We can not say that there are positive or negative trends in the data just by watching this time series either for temperature or precipitation. However, it is clear that there is more variation in the time series of annual precipitation (bottom, Fig. 1) compared to the time series of annual temperature (top, Fig. 1).

<!--- Chunk for plotting the time series for different stations, you need to choose which subset of time series to plot. Dependencies: temp.cl,temp.obs,prec.cl,prec.obs --->
````{r tseries, dev='png', fig.cap="Figure 1. Some time series of temperature (top) and precipitation (bottom) from 1950 to 2016 that we got after cleaning the data."}
# Plot the times series for each station (or some stations)
ys <- rbind(temp.cl[[3]],prec.cl[[3]])
nsts <- c(ncol(temp.obs),ncol(prec.obs))
plot(ys[1,1]:ys[1,2],temp.obs[,1],type="l",las=2,xlab="Year",ylab="Annual temperature",col="tomato",ylim=c(20,80))
  for(i in seq(2,nsts[1],by=25))
    lines(ys[1,1]:ys[1,2],temp.obs[,i],col="tomato")
plot(ys[2,1]:ys[2,2],prec.obs[,1],type="l",las=2,xlab="Year",ylab="Annual precipitation",col="green",ylim=c(20,80))
  for(i in seq(2,nsts[2],by=5))
    lines(ys[2,1]:ys[2,2],prec.obs[,i],col="green")
```

After applying the Mann-Kendall test for all the time series, i.e. for each weather station, we looked at the p-values and classified the values of the scores into three categories: significant negative trend (identified with a value of -1), non-significant trend (0), and significant positive trend (1). The number of stations in each class for the temperature data are: `r table(tscores)`, we can see that more than half of the stations showed a positive trend. The corresponding frequencies for precipitation data are: `r table(pscores)`, where also positive trends are common.
Figure 2 shows the locations of the weather stations that were included in the trend analysis for temperature data. Each point has a color which is assotiated to the result of the Mann-Kendall test: blue points correspont to positive trens (score=1), yellow points have no trend (score=0) and pink points correspond to negative trends (score=-1). It is clear that more weather stations located in the east side of the country were included in the analysis. From these east stations, we can see a mixture of positive and negative trends in the times series, while for west stations positive trends are more abundant. Thus, its seems that in the west side the temperature along the period $1950-2016$ has increased.

<!--- Chunk for plotting the temperature scores from the Mann-Kendall test for all stations. Dependencies: tscores,temp.cl,library maps --->
```{r map-trend-temp, dev='png', fig.cap="Figure 2. Map of the USA with the location of weather stations. Blue points represent stations were there is a significant positive trend in the temperature time series. Yellow points are stations with no significant trend and pink points correspont to stations were a negative trend was found."}
# extract the unique coordinate pairs to plot the stations
temp.sts <- temp.cl[[2]][nrow(temp.obs)*(1:ncol(temp.obs)),]
# plot points at the locations of the stations and color the points according to the score values
# map of the USA with state divisions
map('state', fill = F)
  title("Temperature")
  # positive trends
  points(temp.sts[which(tscores==1),],pch=20,col="turquoise2")
  # no trends
  points(temp.sts[which(tscores==0),],pch=20,col="yellow")
  # negative trends
  points(temp.sts[which(tscores==-1),],pch=20,col="magenta")

```

Similarly, Figure 3 shows the locations of the weather stations that were included in the trend analysis for precipitation data. The three states included in the analysis seem to be  well covered by the weather stations that we kept after cleaning the data. Most of the time series in these states show a positive trend in precipitation, meaning that there is a statistically significant increase in precipitation during the period $1950-2016$.
<!--- Chunk for plotting the precipitation scores from the Mann-Kendall test for all stations. Dependencies: pscores,prec.cl,library maps --->
```{r map-trend-prec, dev='png', fig.cap="Figure 3. Map of the USA with the location of weather stations. Blue points represent stations were there is a significant positive trend in the precipitation time series. Yellow points are stations with no significant trend and pink points correspont to stations were a negative trend was found."}
# extract the unique coordinate pairs to plot the stations
prec.sts <- prec.cl[[2]][nrow(prec.obs)*(1:ncol(prec.obs)),]
# plot points at the locations of the stations and color the points according to the score values
# map of Alabama, Ohio and Tennesse
map('state', fill = F, region=c("alabama","ohio","tennessee"))
  title("Precipitation")
  # positive trends
  points(prec.sts[which(pscores==1),],pch=19,col="turquoise2")
  # no trends
  points(prec.sts[which(pscores==0),],pch=19,col="yellow")
  # negative trends
  points(prec.sts[which(pscores==-1),],pch=19,col="magenta")
```

# Discussion

It is possible that the results described above change if we consider a different set of weather stations in the analysis. Ideally, we would like to have a set of weather stations uniformly distributed along the USA territory. Further, all these stations should be able to record observations for must of the years consired in the period of study but we know that this in not an easy achieve.
Although the results of this study and the evidence provided by the data are not conclusive, they can guide us on how to design a new study to determine if climate change is indeed afecting more the west side of the country compared to the east side.

# References